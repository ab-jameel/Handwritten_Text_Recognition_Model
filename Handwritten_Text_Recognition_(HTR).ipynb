{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG0ZCxlwAtCH"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sbAJdwNDPFv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zasvUV_nIy30"
      },
      "source": [
        "### Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOlGquMEI1P1"
      },
      "outputs": [],
      "source": [
        "class CRNN(nn.Module):\n",
        "    def __init__(self, cnn, lstm, fc):\n",
        "        super().__init__()\n",
        "        self.cnn = cnn\n",
        "        self.lstm = lstm\n",
        "        self.fc = fc\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        b, c, h, w = x.size()\n",
        "\n",
        "        x = x.permute(3, 0, 1, 2)\n",
        "        x = x.reshape(w, b, h * c)\n",
        "\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class HTRDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_root_dir, char_to_idx, img_height=64, img_width=256, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_root_dir = img_root_dir\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.char_to_idx = char_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_rel_path = row['FILENAME']\n",
        "        text = row['IDENTITY']\n",
        "\n",
        "        image_path = os.path.join(self.img_root_dir, image_rel_path)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        image = resize_and_pad(image, self.img_height, self.img_width)\n",
        "\n",
        "        image = image.astype('float32') / 255.0\n",
        "        image = torch.tensor(image).unsqueeze(0)  # shape: [1, H, W]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label_encoded = [self.char_to_idx[c] for c in text if c in self.char_to_idx]\n",
        "        label_tensor = torch.tensor(label_encoded, dtype=torch.long)\n",
        "\n",
        "        return image, label_tensor, len(label_tensor), text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWoIDBsfE8Ex"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPF97J7WE-ac"
      },
      "outputs": [],
      "source": [
        "def build_charset(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    charset = set()\n",
        "    for text in df['IDENTITY']:\n",
        "        charset.update(text)\n",
        "    return sorted(list(charset))\n",
        "\n",
        "def create_mapping(charset):\n",
        "    char_to_idx = {char: idx + 1 for idx, char in enumerate(charset)}\n",
        "    char_to_idx['<BLANK>'] = 0\n",
        "\n",
        "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "    return char_to_idx, idx_to_char\n",
        "\n",
        "def encode_label(text, char_to_idx):\n",
        "    return [char_to_idx[char] for char in text if char in char_to_idx]\n",
        "\n",
        "def decode_prediction(pred, idx_to_char):\n",
        "    pred = pred.permute(1, 0, 2)\n",
        "    pred_labels = torch.argmax(pred, dim=2)\n",
        "    decoded = []\n",
        "    for label_seq in pred_labels:\n",
        "        prev = -1\n",
        "        string = ''\n",
        "        print(label_seq)\n",
        "        for idx in label_seq:\n",
        "            idx = idx.item()\n",
        "            if idx != prev and idx != 0:\n",
        "                string += idx_to_char.get(idx, '')\n",
        "            prev = idx\n",
        "        decoded.append(string)\n",
        "    return decoded\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, labels, label_lengths, texts = zip(*batch)\n",
        "\n",
        "    images = torch.stack(images)\n",
        "\n",
        "    labels_concat = torch.cat(labels)\n",
        "    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n",
        "\n",
        "    return images, labels_concat, label_lengths, texts\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels, label_lengths, texts in tqdm(dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        label_lengths = label_lengths.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        T, B, C = outputs.size()\n",
        "\n",
        "        input_lengths = torch.full(size=(B,), fill_value=T, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        decoded = decode_prediction(outputs.cpu(), idx_to_char)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, criterion, idx_to_char, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, label_lengths, texts in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            label_lengths = label_lengths.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            T, B, C = outputs.size()\n",
        "            input_lengths = torch.full(size=(B,), fill_value=T, dtype=torch.long).to(device)\n",
        "\n",
        "            loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = decode_prediction(outputs.cpu(), idx_to_char)\n",
        "\n",
        "            for pred, true_text in zip(predictions, texts):\n",
        "                if pred == true_text:\n",
        "                    total_correct += 1\n",
        "                total_samples += 1\n",
        "\n",
        "\n",
        "    accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "def resize_and_pad(image, target_height, target_width):\n",
        "    h, w = image.shape\n",
        "    scale = target_height / h\n",
        "    new_w = int(w * scale)\n",
        "    resized = cv2.resize(image, (new_w, target_height))\n",
        "\n",
        "    if new_w < target_width:\n",
        "        pad_w = target_width - new_w\n",
        "        padded = cv2.copyMakeBorder(resized, 0, 0, 0, pad_w, cv2.BORDER_CONSTANT, value=255)\n",
        "    else:\n",
        "        padded = resized[:, :target_width]\n",
        "\n",
        "    return padded\n",
        "\n",
        "def predict_single_image(model, image_path, char_to_idx, idx_to_char, img_height=64, img_width=256, device='cpu'):\n",
        "    model.eval()\n",
        "\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = resize_and_pad(image, img_height, img_width)\n",
        "    image = image.astype('float32') / 255.0\n",
        "    image_tensor = torch.tensor(image).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "\n",
        "    predictions = decode_prediction(output.cpu(), idx_to_char)\n",
        "    return predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuqrWMJUX3eo"
      },
      "source": [
        "#### Used for prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT2w5iN1Xwma"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def extract_handwritten_part(image_path, ignore_ratio=0.09, printed_ratio=0.1):\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    ignore_height = int(height * ignore_ratio)\n",
        "    printed_height = int(height * printed_ratio)\n",
        "\n",
        "    handwritten_text = image[ignore_height + printed_height + 50 : printed_height * 7 + 320, :]\n",
        "    return handwritten_text\n",
        "\n",
        "def save_image(image, path):\n",
        "    cv2.imwrite(path, image)\n",
        "\n",
        "def process_and_clean(images, source_folder, target_folder):\n",
        "    for img_name in images:\n",
        "        img_path = os.path.join(source_folder, img_name)\n",
        "        new_path = os.path.join(target_folder, img_name)\n",
        "\n",
        "        # Extract and save\n",
        "        handwritten_img = extract_handwritten_part(img_path)\n",
        "        save_image(handwritten_img, new_path)\n",
        "\n",
        "        # Delete the original image\n",
        "        os.remove(img_path)\n",
        "\n",
        "def filter_labels(label_path, image_ids, save_path):\n",
        "    with open(label_path, 'r') as infile, open(save_path, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            image_id = line.split('\\t')[0]\n",
        "            if image_id in image_ids:\n",
        "                outfile.write(line)\n",
        "\n",
        "def get_image_ids(folder_path):\n",
        "    return {os.path.splitext(f)[0] for f in os.listdir(folder_path) if f.endswith('.png')}\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBF6sXyVAnsT"
      },
      "source": [
        "# Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To395dBIaTFD"
      },
      "source": [
        "### Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNnfiPH3aa98"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/dataset/'\n",
        "main_labels_path = data_path + 'labels.csv'\n",
        "train_path       = data_path + 'train/'\n",
        "val_path         = data_path + 'val/'\n",
        "test_path        = data_path + 'test/'\n",
        "\n",
        "filtered_labels = {\n",
        "    'train': data_path + 'train_ds.csv',\n",
        "    'val': data_path + 'validate_ds.csv',\n",
        "    'test': data_path + 'test_ds.csv'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Charset"
      ],
      "metadata": {
        "id": "eicbav20QQqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eTw473XRYz2"
      },
      "outputs": [],
      "source": [
        "charset = build_charset(main_labels_path)\n",
        "char_to_idx, idx_to_char = create_mapping(charset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN model"
      ],
      "metadata": {
        "id": "MYDcw6qMQU0M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh1FCNNiVjfG"
      },
      "outputs": [],
      "source": [
        "cnn = nn.Sequential()\n",
        "cnn.add_module('conv1', nn.Conv2d(1, 64, kernel_size=3, padding=1))\n",
        "cnn.add_module('relu1', nn.ReLU())\n",
        "cnn.add_module('pool1', nn.MaxPool2d(2, 2))\n",
        "\n",
        "cnn.add_module('conv2', nn.Conv2d(64, 128, kernel_size=3, padding=1))\n",
        "cnn.add_module('relu2', nn.ReLU())\n",
        "cnn.add_module('pool2', nn.MaxPool2d(2, 2))\n",
        "\n",
        "cnn.add_module('conv3', nn.Conv2d(128, 256, kernel_size=3, padding=1))\n",
        "cnn.add_module('relu3', nn.ReLU())\n",
        "cnn.add_module('conv4', nn.Conv2d(256, 256, kernel_size=3, padding=1))\n",
        "cnn.add_module('relu4', nn.ReLU())\n",
        "cnn.add_module('pool3', nn.MaxPool2d((2, 1), (2, 1)))\n",
        "\n",
        "cnn.add_module('conv5', nn.Conv2d(256, 512, kernel_size=3, padding=1))\n",
        "cnn.add_module('bn1', nn.BatchNorm2d(512))\n",
        "cnn.add_module('relu5', nn.ReLU())\n",
        "cnn.add_module('conv6', nn.Conv2d(512, 512, kernel_size=3, padding=1))\n",
        "cnn.add_module('bn2', nn.BatchNorm2d(512))\n",
        "cnn.add_module('relu6', nn.ReLU())\n",
        "cnn.add_module('pool4', nn.MaxPool2d((2, 1), (2, 1)))\n",
        "\n",
        "num_classes = len(char_to_idx)\n",
        "img_height = 64\n",
        "\n",
        "lstm = nn.LSTM(\n",
        "    input_size=512 * (img_height // 16),\n",
        "    hidden_size=256,\n",
        "    num_layers=2,\n",
        "    bidirectional=True,\n",
        "    batch_first=False\n",
        ")\n",
        "\n",
        "fc = nn.Linear(512, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CRNN(cnn, lstm, fc).to(device)"
      ],
      "metadata": {
        "id": "KhgmSwjPN5Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "VMU3utZKQgas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Augmentation"
      ],
      "metadata": {
        "id": "yQcx9vXPgTWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=4, translate=(0.02, 0.02), scale=(0.95, 1.05), shear=4),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5)),\n",
        "    transforms.RandomErasing(p=0.1, scale=(0.01, 0.03), ratio=(0.3, 3.3), value='random'),\n",
        "])"
      ],
      "metadata": {
        "id": "VtWEqIlTf-9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and Validation"
      ],
      "metadata": {
        "id": "YrAApPgkhIyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHPdBIIb9rbs"
      },
      "outputs": [],
      "source": [
        "train_dataset = HTRDataset(filtered_labels['train'], train_path, char_to_idx, transform=train_transforms)\n",
        "val_dataset = HTRDataset( filtered_labels['val'], val_path, char_to_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss function and optimizer"
      ],
      "metadata": {
        "id": "km0fvWQjQp48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NR_TzqKbxwK"
      },
      "outputs": [],
      "source": [
        "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "cXuY0sKHQua9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-UnxfWYcI5J",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "    train_loss = train_one_epoch(model, train_loader, ctc_loss, optimizer, device)\n",
        "    val_loss, val_acc = validate(model, val_loader, ctc_loss, idx_to_char, device)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Prediction"
      ],
      "metadata": {
        "id": "VboZwzTq1S7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47gbFxJ_9Df7"
      },
      "outputs": [],
      "source": [
        "image_path = test_path + 'TEST_0007.jpg'\n",
        "predicted_text = predict_single_image(model, image_path, char_to_idx, idx_to_char, device=device)\n",
        "\n",
        "print(\"Predicted Text:\", predicted_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}